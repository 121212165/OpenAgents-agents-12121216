# æµ‹è¯•é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
"""
éªŒè¯ä»»åŠ¡å››çš„åŠŸèƒ½ï¼š
1. é”™è¯¯å¤„ç†å’ŒAgentæ¢å¤
2. ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
3. æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•
"""

import asyncio
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
ROOT_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT_DIR))

from loguru import logger
from src.utils.error_handler import (
    AgentRecoveryManager,
    UserFriendlyMessages,
    ErrorCategory,
    ErrorSeverity,
    register_agent_for_recovery,
    handle_agent_error,
    is_agent_healthy,
    with_error_handling
)
from src.utils.common import (
    setup_logger,
    monitor_performance,
    format_performance_report,
    DetailedLogger,
    get_performance_monitor
)


# ==================== æµ‹è¯•Agent ====================

class MockAgent:
    """æ¨¡æ‹ŸAgentç”¨äºæµ‹è¯•"""

    def __init__(self, name: str, should_fail: bool = False):
        self.name = name
        self.should_fail = should_fail
        self.call_count = 0
        self.failure_count = 0

    async def process_request(self, request: str) -> str:
        """å¤„ç†è¯·æ±‚"""
        self.call_count += 1

        if self.should_fail and self.call_count <= 2:
            self.failure_count += 1
            raise ConnectionError(f"{self.name}: ç½‘ç»œè¿æ¥å¤±è´¥")

        return f"{self.name} å¤„ç†äº†: {request}"

    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        return not self.should_fail or self.failure_count >= 2

    async def restart(self):
        """é‡å¯Agent"""
        logger.info(f"{self.name} æ­£åœ¨é‡å¯...")
        await asyncio.sleep(0.1)
        self.should_fail = False
        logger.info(f"{self.name} é‡å¯å®Œæˆ")


# ==================== æµ‹è¯•å‡½æ•° ====================

async def test_user_friendly_messages():
    """æµ‹è¯•ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯"""
    print("\n" + "="*60)
    print("æµ‹è¯•1: ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯")
    print("="*60)

    test_cases = [
        (ErrorCategory.NETWORK, "ç½‘ç»œè¿æ¥è¶…æ—¶"),
        (ErrorCategory.API, "APIè°ƒç”¨å¤±è´¥"),
        (ErrorCategory.DATA_SOURCE, "æ•°æ®æºä¸å¯ç”¨"),
        (ErrorCategory.AGENT, "Agentå¤„ç†å¼‚å¸¸"),
        (ErrorCategory.LLM, "LLMè°ƒç”¨å¤±è´¥"),
        (ErrorCategory.TIMEOUT, "è¯·æ±‚è¶…æ—¶")
    ]

    for category, detail in test_cases:
        message = UserFriendlyMessages.get_message(category, detail)
        print(f"\n{category.value.upper()}:")
        print(message[:300] + "...")
        print("-" * 60)

    print("âœ… ç”¨æˆ·å‹å¥½æ¶ˆæ¯æµ‹è¯•é€šè¿‡")


async def test_agent_recovery():
    """æµ‹è¯•Agentæ¢å¤æœºåˆ¶"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: Agentè‡ªåŠ¨æ¢å¤æœºåˆ¶")
    print("="*60)

    # åˆ›å»ºæ¢å¤ç®¡ç†å™¨
    manager = AgentRecoveryManager()

    # åˆ›å»ºä¼šå¤±è´¥çš„Agent
    failing_agent = MockAgent("failing_agent", should_fail=True)
    manager.register_agent("failing_agent", failing_agent)

    print("\n1ï¸âƒ£ æ¨¡æ‹ŸAgenté”™è¯¯...")

    # è§¦å‘å¤šæ¬¡é”™è¯¯
    for i in range(3):
        try:
            await failing_agent.process_request(f"è¯·æ±‚{i+1}")
        except Exception as e:
            await manager.handle_error("failing_agent", e)
            print(f"  âŒ é”™è¯¯ {i+1}: {str(e)[:50]}")

    # æ£€æŸ¥çŠ¶æ€
    status = manager.get_agent_status("failing_agent")
    print(f"\nğŸ“Š AgentçŠ¶æ€:")
    print(f"  é”™è¯¯æ¬¡æ•°: {status['error_count']}")
    print(f"  çŠ¶æ€: {status['status']}")
    print(f"  å†·å´ä¸­: {status['in_cooldown']}")

    print("\n2ï¸âƒ£ ç­‰å¾…Agentæ¢å¤...")
    await asyncio.sleep(3)  # ç­‰å¾…æ¢å¤å®Œæˆ

    # æ£€æŸ¥æ˜¯å¦æ¢å¤
    if is_agent_healthy("failing_agent"):
        print("  âœ… Agentå·²æ¢å¤")

        # å°è¯•å†æ¬¡è°ƒç”¨
        try:
            result = await failing_agent.process_request("æ¢å¤åçš„è¯·æ±‚")
            print(f"  âœ… è°ƒç”¨æˆåŠŸ: {result}")
        except Exception as e:
            print(f"  âŒ ä»ç„¶å¤±è´¥: {e}")
    else:
        print("  âš ï¸ Agentä»åœ¨æ¢å¤ä¸­")

    print("\nâœ… Agentæ¢å¤æµ‹è¯•å®Œæˆ")


async def test_error_handling_decorator():
    """æµ‹è¯•é”™è¯¯å¤„ç†è£…é¥°å™¨"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: é”™è¯¯å¤„ç†è£…é¥°å™¨")
    print("="*60)

    manager = AgentRecoveryManager()
    test_agent = MockAgent("test_agent")
    manager.register_agent("test_agent", test_agent)

    @with_error_handling(manager, "test_agent", fallback_result="é™çº§å“åº”")
    async def risky_function():
        """å¯èƒ½å¤±è´¥çš„é£é™©å‡½æ•°"""
        await asyncio.sleep(0.1)
        if time.time() % 2 < 1:  # 50%å¤±è´¥ç‡
            raise ValueError("æ¨¡æ‹Ÿçš„éšæœºé”™è¯¯")
        return "æ­£å¸¸å“åº”"

    print("\n1ï¸âƒ£ æµ‹è¯•æ­£å¸¸æƒ…å†µ:")
    for i in range(5):
        result = await risky_function()
        print(f"  è°ƒç”¨ {i+1}: {result}")

    print("\n2ï¸âƒ£ AgentçŠ¶æ€:")
    status = manager.get_agent_status("test_agent")
    print(f"  é”™è¯¯æ¬¡æ•°: {status['error_count']}")

    print("\nâœ… è£…é¥°å™¨æµ‹è¯•å®Œæˆ")


async def test_performance_monitoring():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§"""
    print("\n" + "="*60)
    print("æµ‹è¯•4: æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—")
    print("="*60)

    monitor = get_performance_monitor()

    @monitor_performance("fast_function")
    async def fast_function():
        """å¿«é€Ÿå‡½æ•°"""
        await asyncio.sleep(0.01)
        return "done"

    @monitor_performance("slow_function")
    async def slow_function():
        """æ…¢å‡½æ•°"""
        await asyncio.sleep(0.5)
        return "done"

    @monitor_performance("failing_function")
    async def failing_function():
        """ä¼šå¤±è´¥çš„å‡½æ•°"""
        await asyncio.sleep(0.1)
        raise RuntimeError("æ¨¡æ‹Ÿé”™è¯¯")

    print("\n1ï¸âƒ£ æ‰§è¡Œæµ‹è¯•å‡½æ•°...")

    # æ‰§è¡Œå„ç§å‡½æ•°
    for _ in range(5):
        await fast_function()

    for _ in range(3):
        await slow_function()

    for _ in range(2):
        try:
            await failing_function()
        except:
            pass

    print("\n2ï¸âƒ£ æ€§èƒ½ç»Ÿè®¡:")
    stats = monitor.get_stats()
    for name, stat in stats.items():
        print(f"\n  {name}:")
        print(f"    è°ƒç”¨æ¬¡æ•°: {stat['count']}")
        print(f"    å¹³å‡è€—æ—¶: {stat['avg_time']}s")
        print(f"    æœ€å¤§è€—æ—¶: {stat['max_time']}s")
        if stat['error_rate'] > 0:
            print(f"    âŒ é”™è¯¯ç‡: {stat['error_rate']}%")

    print("\n3ï¸âƒ£ æ€§èƒ½æŠ¥å‘Š:")
    report = format_performance_report()
    print(report[:500] + "...")

    print("\nâœ… æ€§èƒ½ç›‘æ§æµ‹è¯•å®Œæˆ")


async def test_detailed_logging():
    """æµ‹è¯•è¯¦ç»†æ—¥å¿—è®°å½•"""
    print("\n" + "="*60)
    print("æµ‹è¯•5: è¯¦ç»†æ—¥å¿—è®°å½•")
    print("="*60)

    print("\n1ï¸âƒ£ è®°å½•Agentè°ƒç”¨...")
    DetailedLogger.log_agent_call(
        agent_name="router_agent",
        method="process_query",
        parameters={"query": "Uziåœ¨ç›´æ’­å—ï¼Ÿ"},
        result={"intent": "ç›´æ’­æŸ¥è¯¢", "confidence": 0.9},
        duration=0.123,
        error=None
    )

    print("\n2ï¸âƒ£ è®°å½•æ•°æ®æºæŸ¥è¯¢...")
    DetailedLogger.log_data_source_query(
        source="mock_data",
        query_type="streams",
        parameters={"first": 10},
        result_count=5,
        cached=True,
        duration=0.05
    )

    print("\n3ï¸âƒ£ è®°å½•LLMè°ƒç”¨...")
    DetailedLogger.log_llm_call(
        prompt_type="intent_classification",
        prompt_length=150,
        response_length=80,
        cached=False,
        duration=0.8
    )

    print("\n4ï¸âƒ£ è®°å½•ç”¨æˆ·æŸ¥è¯¢...")
    DetailedLogger.log_user_query(
        query="ç”Ÿæˆä»Šæ—¥ç®€æŠ¥",
        intent="ç®€æŠ¥ç”Ÿæˆ",
        confidence=0.85,
        agents_used=["briefing_agent", "live_monitor"],
        duration=1.5,
        success=True
    )

    print("\n5ï¸âƒ£ è®°å½•é”™è¯¯æƒ…å†µ...")
    DetailedLogger.log_agent_call(
        agent_name="data_source_agent",
        method="get_live_streams",
        parameters={"user_login": "unknown"},
        result=None,
        duration=5.0,
        error="ç”¨æˆ·ä¸å­˜åœ¨"
    )

    print("\nâœ… æ—¥å¿—è®°å½•æµ‹è¯•å®Œæˆ - è¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶")


async def test_error_statistics():
    """æµ‹è¯•é”™è¯¯ç»Ÿè®¡"""
    print("\n" + "="*60)
    print("æµ‹è¯•6: é”™è¯¯ç»Ÿè®¡å’Œåˆ†æ")
    print("="*60)

    manager = AgentRecoveryManager()

    # æ³¨å†Œå¤šä¸ªAgent
    agents = ["agent_a", "agent_b", "agent_c"]
    for agent_name in agents:
        manager.register_agent(agent_name, MockAgent(agent_name))

    print("\n1ï¸âƒ£ æ¨¡æ‹Ÿå„ç§é”™è¯¯...")

    # ä¸ºæ¯ä¸ªAgentè§¦å‘ä¸åŒç±»å‹çš„é”™è¯¯
    errors = [
        ("agent_a", ConnectionError("ç½‘ç»œè¶…æ—¶")),
        ("agent_a", TimeoutError("è¯·æ±‚è¶…æ—¶")),
        ("agent_b", ValueError("æ— æ•ˆå‚æ•°")),
        ("agent_b", RuntimeError("å¤„ç†å¤±è´¥")),
        ("agent_c", ConnectionError("APIè¿æ¥å¤±è´¥")),
    ]

    for agent_name, error in errors:
        await manager.handle_error(agent_name, error)

    print("\n2ï¸âƒ£ é”™è¯¯ç»Ÿè®¡:")
    stats = manager.get_error_statistics()
    for agent_name, agent_stats in stats.items():
        print(f"\n  {agent_name}:")
        for category, count in agent_stats.items():
            print(f"    {category}: {count}")

    print("\n3ï¸âƒ£ Agentå¥åº·çŠ¶æ€:")
    all_status = manager.get_agent_status()
    for agent_name, status in all_status.items():
        healthy = is_agent_healthy(agent_name)
        icon = "ğŸŸ¢" if healthy else "ğŸ”´"
        print(f"  {icon} {agent_name}: {status['error_count']} ä¸ªé”™è¯¯")

    print("\nâœ… é”™è¯¯ç»Ÿè®¡æµ‹è¯•å®Œæˆ")


async def test_integration():
    """é›†æˆæµ‹è¯• - æµ‹è¯•æ‰€æœ‰ç»„ä»¶ååŒå·¥ä½œ"""
    print("\n" + "="*60)
    print("æµ‹è¯•7: é›†æˆæµ‹è¯•")
    print("="*60)

    print("\n1ï¸âƒ£ åˆå§‹åŒ–ç³»ç»Ÿ...")

    # æ³¨å†ŒAgentåˆ°å…¨å±€æ¢å¤ç®¡ç†å™¨
    router = MockAgent("router")
    data_source = MockAgent("data_source")
    briefing = MockAgent("briefing")

    register_agent_for_recovery("router", router)
    register_agent_for_recovery("data_source", data_source)
    register_agent_for_recovery("briefing", briefing)

    print("  âœ… Agentå·²æ³¨å†Œ")

    print("\n2ï¸âƒ£ æ¨¡æ‹Ÿç”¨æˆ·æŸ¥è¯¢æµç¨‹...")

    @monitor_performance("user_query_flow")
    async def handle_user_query(query: str):
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„å®Œæ•´æµç¨‹"""
        logger.info(f"å¤„ç†æŸ¥è¯¢: {query}")

        # è®°å½•æŸ¥è¯¢
        DetailedLogger.log_user_query(
            query=query,
            intent="æµ‹è¯•æ„å›¾",
            confidence=0.8,
            agents_used=["router", "data_source"],
            duration=0.0,
            success=True
        )

        # è°ƒç”¨Agent
        try:
            result = await router.process_request(query)
            return result
        except Exception as e:
            # å¤„ç†é”™è¯¯
            error_msg = await handle_agent_error("router", e)
            return error_msg

    # æ‰§è¡Œå¤šä¸ªæŸ¥è¯¢
    queries = ["æŸ¥è¯¢1", "æŸ¥è¯¢2", "æŸ¥è¯¢3"]
    for query in queries:
        print(f"\n  å¤„ç†: {query}")
        result = await handle_user_query(query)
        print(f"  ç»“æœ: {result[:50]}...")

    print("\n3ï¸âƒ£ ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š:")

    # æ€§èƒ½æŠ¥å‘Š
    print("\nğŸ“Š æ€§èƒ½æŠ¥å‘Š:")
    print(format_performance_report())

    # AgentçŠ¶æ€
    print("\nğŸ¤– AgentçŠ¶æ€:")
    from src.utils.error_handler import global_recovery_manager
    all_status = global_recovery_manager.get_agent_status()
    for agent_name, status in all_status.items():
        healthy = is_agent_healthy(agent_name)
        icon = "ğŸŸ¢" if healthy else "ğŸ”´"
        print(f"  {icon} {agent_name}: é”™è¯¯æ•°={status['error_count']}, çŠ¶æ€={status['status']}")

    print("\nâœ… é›†æˆæµ‹è¯•å®Œæˆ")


# ==================== ä¸»æµ‹è¯•å‡½æ•° ====================

async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("[TEST] Task 4 Test Suite - Error Handling, Recovery and Logging")
    print("="*70)

    # è®¾ç½®æ—¥å¿—
    setup_logger(log_level="INFO")

    try:
        # è¿è¡Œæµ‹è¯•
        await test_user_friendly_messages()
        await test_agent_recovery()
        await test_error_handling_decorator()
        await test_performance_monitoring()
        await test_detailed_logging()
        await test_error_statistics()
        await test_integration()

        print("\n" + "="*70)
        print("[PASS] All tests passed!")
        print("="*70)

        print("\n[SUMMARY] Test Summary:")
        print("  1. [OK] User-friendly error messages")
        print("  2. [OK] Agent auto-recovery mechanism")
        print("  3. [OK] Error handling decorator")
        print("  4. [OK] Performance monitoring and statistics")
        print("  5. [OK] Detailed logging")
        print("  6. [OK] Error statistics and analysis")
        print("  7. [OK] System integration testing")

        print("\n[TIP] Please check logs/yougame.log for detailed logs")

    except Exception as e:
        logger.error(f"[ERROR] Test failed: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(run_all_tests())
